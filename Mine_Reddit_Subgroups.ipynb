{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mine Reddit Subgroups",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Josh-Been/Mining-Reddit-Instagram/blob/master/Mine_Reddit_Subgroups.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8neWBpvAC3ET",
        "colab_type": "text"
      },
      "source": [
        "![Baylor Libraries: Digital Scholarship](https://cpb-us-w2.wpmucdn.com/blogs.baylor.edu/dist/7/7192/files/2019/08/cropped-DigitalScholarshipblog_header-2019-08-30-1.jpg)\n",
        "\n",
        "# Mine Reddit Subgroups\n",
        "\n",
        "Primary Libraries Used\n",
        "\n",
        "*   Python Reddit Wrapper [PRAW: The Python Reddit API Wrapper](https://praw.readthedocs.io/en/latest/)\n",
        "*   OCR Text from Images [Github: tesseract-ocr](https://github.com/tesseract-ocr/tesseract)\n",
        "*   Recognize Objects in Images [Github: ImageAI](https://github.com/OlafenwaMoses/ImageAI)\n",
        "\n",
        "Thank you to the following helpful guides\n",
        "\n",
        "*   [Felippe Rodrigues: How to scrape Reddit with Python](https://www.storybench.org/how-to-scrape-reddit-with-python/)\n",
        "*   [Bhadresh Savani: OCR from Image using Pytesseract in Python on Colab Notebook?](https://medium.com/@bhadreshpsavani/how-to-use-tesseract-library-for-ocr-in-google-colab-notebook-5da5470e4fe0)\n",
        "*   [Object Detection with 10 lines of code](https://towardsdatascience.com/object-detection-with-10-lines-of-code-d6cb4d86f606)\n",
        "\n",
        "02/2020, Josh Been"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuLs09fBD1s6",
        "colab_type": "text"
      },
      "source": [
        "# Step 1 - Install PRAW\n",
        "\n",
        "Run the following snippet. Wait until it specifies complete before moving to the next snippet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVrSi0OFGT-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cursor='  >> '\n",
        "print(cursor,'Installing PRAW')\n",
        "from google.colab import output\n",
        "try:\n",
        "  import praw\n",
        "except:\n",
        "  !pip install praw\n",
        "  import praw\n",
        "output.clear()\n",
        "print(cursor,'Installing PRAW')\n",
        "print(cursor, 'PRAW Installation Complete')\n",
        "\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "\n",
        "print(cursor, 'Complete. Move onto the next snippet.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjdG80J6Eexk",
        "colab_type": "text"
      },
      "source": [
        "# Step 2 - Enter 5 Reddit API Strings\n",
        "\n",
        "Specify the following 5 strings.\n",
        "\n",
        "\n",
        "\n",
        "1.   Head to [Reddit Apps](https://www.reddit.com/prefs/apps)\n",
        "2.   Sign In\n",
        "3.   Click EDIT on an existing app **OR** Click the create app or create another app button at the bottom left\n",
        "   * Name the application\n",
        "   * Select the **script** option\n",
        "   * Enter http://localhost:8080 in the redirect uri field\n",
        "\n",
        "<img src=\"https://i.ibb.co/cLTkV7b/reddit-api.png\" width=75%>\n",
        "\n",
        "or [go here](https://researchguides.baylor.edu/c.php?g=980986)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TwfD86-H4dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reddit = praw.Reddit(client_id='', client_secret='', user_agent='', username='', password='')\n",
        "print(cursor, 'Complete. Move onto the next snippet.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw3QGvxVFFIN",
        "colab_type": "text"
      },
      "source": [
        "# Step 3 - Specify Subreddit\n",
        "\n",
        "Specify the name of the subreddit to search.\n",
        "\n",
        "Then run the snippet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn7XrHqsIrao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subreddit = reddit.subreddit('')   # Enter subreddit between the ''\n",
        "print(cursor, 'Complete. Move onto the next snippet.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T38akEvFb_c",
        "colab_type": "text"
      },
      "source": [
        "# Step 4 - Type and Amount of Posts to Return\n",
        "\n",
        "Specify the type and amouont of posts to return. Each subreddit has five different ways of organizing the topics created by redditors: **.hot**, **.new**, **.controversial**, **.top**, and **.gilded**. You can also use **.search**(\"SEARCH_KEYWORDS\") to get only results matching an engine search.\n",
        "\n",
        "Then run the snippet. This snippet will test whether your authentication and search were successful by attempting to request 1 post."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slqt9-e0JBNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_subreddit = subreddit.top(limit=100)\n",
        "\n",
        "for submission in subreddit.top(limit=1):\n",
        "    print(cursor, submission.title, submission.id)\n",
        "\n",
        "print(cursor, 'Complete. Move onto the next snippet.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0x2SsuJG7Xf",
        "colab_type": "text"
      },
      "source": [
        "# Step 5 - Write Search Results Metadata to REDDIT.csv\n",
        "\n",
        "If the last snippet successfully returned 1 post, this snippet should successfully extract the full search request and save to a comma delimited .csv spreadsheet file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihG5myU6MxTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime as dt\n",
        "topics_dict = { \"title\":[], \"score\":[], \"id\":[], \"url\":[], \"comms_num\": [], \"created\": [], \"body\":[], \"img\":[]}\n",
        "\n",
        "for submission in top_subreddit:\n",
        "    topics_dict[\"title\"].append(submission.title)\n",
        "    topics_dict[\"score\"].append(submission.score)\n",
        "    topics_dict[\"id\"].append(submission.id)\n",
        "    topics_dict[\"url\"].append(submission.url)\n",
        "    topics_dict[\"comms_num\"].append(submission.num_comments)\n",
        "    topics_dict[\"created\"].append(submission.created)\n",
        "    topics_dict[\"body\"].append(submission.selftext.replace('\\n',' '))\n",
        "    try:\n",
        "        topics_dict[\"img\"].append(submission.url.split('/')[-1])\n",
        "    except:\n",
        "        topics_dict[\"img\"].append('')\n",
        "\n",
        "topics_data = pd.DataFrame(topics_dict)\n",
        "\n",
        "def get_date(created):\n",
        "    return dt.datetime.fromtimestamp(created)\n",
        "\n",
        "_timestamp = topics_data[\"created\"].apply(get_date)\n",
        "\n",
        "topics_data = topics_data.assign(timestamp = _timestamp)\n",
        "\n",
        "topics_data.to_csv('REDDIT.csv', index=False) \n",
        "print(cursor, 'Created REDDIT.csv with', len(topics_data), 'records.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmc0HYwjXov-",
        "colab_type": "text"
      },
      "source": [
        "# Step 6 - Download Accompanying Images\n",
        "\n",
        "Run the following code snippet to download all images linked in the subreddit extract created above.\n",
        "\n",
        "A new folder is created with the images. The folder name is the date/time stamp. A zip compressed file for easy downloading is also generated with the same date/time stamp."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJBXSCe9TmC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, shutil, urllib.request\n",
        "from google.colab import files\n",
        "\n",
        "imagetypes=['jpg','png','tif','bmp','gif']\n",
        "\n",
        "print(cursor, 'Downloading images')\n",
        "import datetime\n",
        "dt = str(datetime.datetime.now())\n",
        "os.mkdir(dt)\n",
        "\n",
        "for img in topics_dict['url']:\n",
        "  if img[-3:] in imagetypes:\n",
        "    filename = img.split('/')[-1].split('?')[0]\n",
        "    try:\n",
        "      urllib.request.urlretrieve(img, dt+'/'+filename)\n",
        "    except:\n",
        "      print('Skipping image due to error', img)\n",
        "\n",
        "shutil.make_archive(dt, 'zip', dt)\n",
        "print(cursor, 'Directory with images created.')\n",
        "print(cursor, 'Zipped file created.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVHkEum7r7Bo",
        "colab_type": "text"
      },
      "source": [
        "# Step 7 - OCR Text From Images\n",
        "\n",
        "Extract text from images. Clean text and then write to new CSV spreadsheet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q5veUyl3bQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(cursor, 'Install Tesseract OCR')\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "output.clear()\n",
        "\n",
        "print(cursor, 'Install Tesseract OCR')\n",
        "print(cursor, 'Installation completed')\n",
        "print(cursor, 'Processing images')\n",
        "import pytesseract, shutil, os, random, glob, spacy\n",
        "try:\n",
        "    from PIL import Image\n",
        "except ImportError:\n",
        "    import Image\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "location = dt\n",
        "fileset = [file for file in glob.glob(location + \"**/*\", recursive=True)]\n",
        "i=1\n",
        "imgtxt=[]\n",
        "urls=[]\n",
        "for img in fileset:\n",
        "    word_list=[]\n",
        "    try:\n",
        "        obtained_txt=pytesseract.image_to_string(Image.open(img))\n",
        "    except:\n",
        "        print(cursor, 'Sorry, problem occurred with', img, 'Skipping...')\n",
        "        obtained_text=''\n",
        "    obtained_text=obtained_txt.lower()\n",
        "    doc=nlp(obtained_txt.replace('\\n',' ').replace('\\r',' '))\n",
        "    for token in doc:\n",
        "        word_list.append(token.text.lower())\n",
        "    extractedInformation=' '.join(word_list)\n",
        "    print(cursor, i,'/',len(fileset))\n",
        "    imgtxt.append(extractedInformation)\n",
        "    urls.append(img.split('/')[1])\n",
        "    i+=1\n",
        "\n",
        "df_img = pd.DataFrame(imgtxt, columns =['img2txt'])\n",
        "df_img['img']=urls\n",
        "df_merged=pd.merge(topics_data, df_img, on='img', how='left')\n",
        "df_merged.to_csv('REDDIT_OCR.csv', index=False)\n",
        "print(cursor, 'Completed. Written to REDDIT_OCR.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl0wpTNpbkPH",
        "colab_type": "text"
      },
      "source": [
        "# Step 8 - Install ImageAI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQhmlUmobv06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(cursor,'Installing imageai')\n",
        "!pip install imageai --upgrade\n",
        "output.clear()\n",
        "print(cursor,'Installing imageai')\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve (\"https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/resnet50_coco_best_v2.0.1.h5\", \"resnet50_coco_best_v2.0.1.h5\")\n",
        "print(cursor, 'Completed')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFK81vCXbxgv",
        "colab_type": "text"
      },
      "source": [
        "# Step 9 - Recognize Objects\n",
        "\n",
        "[AI Details](https://github.com/OlafenwaMoses/ImageAI/blob/master/imageai/Detection/README.md)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ig00j38b29D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from imageai.Detection import ObjectDetection\n",
        "import os\n",
        "from IPython.display import Image\n",
        "\n",
        "recognized_items={}\n",
        "\n",
        "fileset = [file for file in glob.glob(location + \"**/*\", recursive=True)]\n",
        "i=0\n",
        "imgtxt=[]\n",
        "urls=[]\n",
        "\n",
        "# [:10] returns the first 10 images for speed\n",
        "\n",
        "print(cursor, 'Processing Images')\n",
        "for img in fileset[:10]:\n",
        "    if not os.path.isfile(location+'/resnet50_coco_best_v2.0.1.h5'): \n",
        "        shutil.move('resnet50_coco_best_v2.0.1.h5', location+'/resnet50_coco_best_v2.0.1.h5')\n",
        "    execution_path = location\n",
        "\n",
        "    i+=1 \n",
        "    img_=img.split('/')[1]\n",
        "    print(cursor, 'processing image', i)\n",
        "    detector = ObjectDetection()\n",
        "    detector.setModelTypeAsRetinaNet()\n",
        "    detector.setModelPath( os.path.join(execution_path , \"resnet50_coco_best_v2.0.1.h5\"))\n",
        "    detector.loadModel()\n",
        "    detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , img_), output_image_path=os.path.join(execution_path , img_.replace('.jpg','_new.jpg')))\n",
        "    if i==1:\n",
        "        output.clear()\n",
        "        print(cursor, 'Processing Images')\n",
        "        print(cursor, 'processing image', i)\n",
        "    if len(detections)>0:\n",
        "        display(Image(img.replace('.jpg','_new.jpg')))\n",
        "        for eachObject in detections:\n",
        "            print(eachObject[\"name\"] , \" : \" , eachObject[\"percentage_probability\"] )\n",
        "            if eachObject[\"name\"] in recognized_items:\n",
        "                recognized_items[eachObject[\"name\"]]+=1\n",
        "            else:\n",
        "                recognized_items[eachObject[\"name\"]]=1\n",
        "    else:\n",
        "        print(cursor, 'No objects recognized')\n",
        "shutil.move(location+'/resnet50_coco_best_v2.0.1.h5', 'resnet50_coco_best_v2.0.1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HdePQzcjIpZ",
        "colab_type": "text"
      },
      "source": [
        "# Step 10 - Column Chart of Recognized Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHmIge_KjODG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pylab as pl\n",
        "import numpy as np\n",
        "\n",
        "X = np.arange(len(recognized_items))\n",
        "pl.bar(X, recognized_items.values(), align='center', width=0.5)\n",
        "pl.xticks(X, recognized_items.keys())\n",
        "ymax = max(recognized_items.values()) + 1\n",
        "pl.ylim(0, ymax)\n",
        "pl.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}